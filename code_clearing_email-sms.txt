def transform_text(text):

  text = text.lower()

  text = nltk.word_tokenize(text) #for Tokenization (breaking the code)

   

  y = []

  for i in text:

    if i.isalnum():

      y.append(i)

   

  text = y[:]

  y.clear()

   

  for i in text:

    if i not in stopwords.words('english') and i not in string.punctuation:

      y.append(i)

       

  text = y[:]

  y.clear()

   

  for i in text:

    y.append(ps.stem(i))

   

       

  return " ".join(y) let me know how's it happening.

expand_more

volume_up